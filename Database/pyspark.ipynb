{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2020</td><td>application_1572292571909_0502</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://rapid-778.oit.duke.edu:8088/proxy/application_1572292571909_0502/\">Link</a></td><td><a target=\"_blank\" href=\"http://rapid-784.oit.duke.edu:8042/node/containerlogs/container_e26_1572292571909_0502_01_000001/user12064\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "%%spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'driverMemory': '2048M', 'executorCores': 2, 'proxyUser': 'user12064', 'conf': {'spark.master': 'yarn-client'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2016</td><td>application_1572292571909_0498</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://rapid-778.oit.duke.edu:8088/proxy/application_1572292571909_0498/\">Link</a></td><td><a target=\"_blank\" href=\"http://rapid-782.oit.duke.edu:8042/node/containerlogs/container_e26_1572292571909_0498_01_000001/user12031\">Link</a></td><td></td></tr><tr><td>2017</td><td>application_1572292571909_0499</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://rapid-778.oit.duke.edu:8088/proxy/application_1572292571909_0499/\">Link</a></td><td><a target=\"_blank\" href=\"http://rapid-785.oit.duke.edu:8042/node/containerlogs/container_e26_1572292571909_0499_01_000001/user12020\">Link</a></td><td></td></tr><tr><td>2018</td><td>application_1572292571909_0500</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://rapid-778.oit.duke.edu:8088/proxy/application_1572292571909_0500/\">Link</a></td><td><a target=\"_blank\" href=\"http://rapid-788.oit.duke.edu:8042/node/containerlogs/container_e26_1572292571909_0500_01_000001/user12058\">Link</a></td><td></td></tr><tr><td>2019</td><td>application_1572292571909_0501</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://rapid-778.oit.duke.edu:8088/proxy/application_1572292571909_0501/\">Link</a></td><td><a target=\"_blank\" href=\"http://rapid-790.oit.duke.edu:8042/node/containerlogs/container_e26_1572292571909_0501_01_000001/user12032\">Link</a></td><td></td></tr><tr><td>2020</td><td>application_1572292571909_0502</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://rapid-778.oit.duke.edu:8088/proxy/application_1572292571909_0502/\">Link</a></td><td><a target=\"_blank\" href=\"http://rapid-784.oit.duke.edu:8042/node/containerlogs/container_e26_1572292571909_0502_01_000001/user12064\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"ain\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can\", \"couldn\", \"couldn't\", \"d\", \"did\", \"didn\", \"didn't\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn\", \"hadn't\", \"has\", \"hasn\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"i\", \"if\", \"in\", \"into\", \"is\", \"isn\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"just\", \"ll\", \"m\", \"ma\", \"me\", \"mightn\", \"mightn't\", \"more\", \"most\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"needn\", \"needn't\", \"no\", \"nor\", \"not\", \"now\", \"o\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"re\", \"s\", \"same\", \"shan\", \"shan't\", \"she\", \"she's\", \"should\", \"should've\", \"shouldn\", \"shouldn't\", \"so\", \"some\", \"such\", \"t\", \"than\", \"that\", \"that'll\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"ve\", \"very\", \"was\", \"wasn\", \"wasn't\", \"we\", \"were\", \"weren\", \"weren't\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"will\", \"with\", \"won\", \"won't\", \"wouldn\", \"wouldn't\", \"y\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"could\", \"he'd\", \"he'll\", \"he's\", \"here's\", \"how's\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"let's\", \"ought\", \"she'd\", \"she'll\", \"that's\", \"there's\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", \"would\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 hdfs hdfs     496309 2018-10-11 11:04 /data/texts/Portrait.txt\n",
      "-rw-r--r--   3 hdfs hdfs    1580890 2018-10-11 11:04 /data/texts/Ulysses.txt"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd = 'hdfs dfs -ls /data/texts'.split() \n",
    "files = subprocess.check_output(cmd).strip().split('\\n')\n",
    "for path in files:\n",
    "    print (path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               value|                file|\n",
      "+--------------------+--------------------+\n",
      "|                    |hdfs://rapid-777....|\n",
      "|The Project Guten...|hdfs://rapid-777....|\n",
      "|                    |hdfs://rapid-777....|\n",
      "|This eBook is for...|hdfs://rapid-777....|\n",
      "|no restrictions w...|hdfs://rapid-777....|\n",
      "|it under the term...|hdfs://rapid-777....|\n",
      "|eBook or online a...|hdfs://rapid-777....|\n",
      "|                    |hdfs://rapid-777....|\n",
      "|                    |hdfs://rapid-777....|\n",
      "|      Title: Ulysses|hdfs://rapid-777....|\n",
      "|                    |hdfs://rapid-777....|\n",
      "| Author: James Joyce|hdfs://rapid-777....|\n",
      "|                    |hdfs://rapid-777....|\n",
      "|Release Date: Aug...|hdfs://rapid-777....|\n",
      "|Last Updated: Aug...|hdfs://rapid-777....|\n",
      "|                    |hdfs://rapid-777....|\n",
      "|   Language: English|hdfs://rapid-777....|\n",
      "|                    |hdfs://rapid-777....|\n",
      "|Character set enc...|hdfs://rapid-777....|\n",
      "|                    |hdfs://rapid-777....|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "raw_lines = spark.read.text('/data/texts')\\\n",
    "    .withColumn('file', f.input_file_name())\n",
    "raw_lines.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|               value|   book|\n",
      "+--------------------+-------+\n",
      "|                    |Ulysses|\n",
      "|The Project Guten...|Ulysses|\n",
      "|                    |Ulysses|\n",
      "|This eBook is for...|Ulysses|\n",
      "|no restrictions w...|Ulysses|\n",
      "|it under the term...|Ulysses|\n",
      "|eBook or online a...|Ulysses|\n",
      "|                    |Ulysses|\n",
      "|                    |Ulysses|\n",
      "|      Title: Ulysses|Ulysses|\n",
      "|                    |Ulysses|\n",
      "| Author: James Joyce|Ulysses|\n",
      "|                    |Ulysses|\n",
      "|Release Date: Aug...|Ulysses|\n",
      "|Last Updated: Aug...|Ulysses|\n",
      "|                    |Ulysses|\n",
      "|   Language: English|Ulysses|\n",
      "|                    |Ulysses|\n",
      "|Character set enc...|Ulysses|\n",
      "|                    |Ulysses|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "lines_by_book = raw_lines \\\n",
    "    .withColumn('book', f.regexp_extract('file', '^.*/(.*)\\.txt$', 1))\\\n",
    "    .drop('file')\n",
    "lines_by_book.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|    book|sum(count)|\n",
      "+--------+----------+\n",
      "|Portrait|     88641|\n",
      "| Ulysses|    271297|\n",
      "+--------+----------+"
     ]
    }
   ],
   "source": [
    "lines_by_book_1 = lines_by_book.withColumn('count', f.size(f.split(f.col('value'), ' ')))\n",
    "lines_by_book_1 = lines_by_book_1.where(f.col('value')!= '')\n",
    "lines_by_book_1.groupby('book').agg({'count':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|   book|lower(trim(word))|\n",
      "+-------+-----------------+\n",
      "|Ulysses|              the|\n",
      "|Ulysses|          project|\n",
      "|Ulysses|        gutenberg|\n",
      "|Ulysses|            ebook|\n",
      "|Ulysses|               of|\n",
      "|Ulysses|         ulysses,|\n",
      "|Ulysses|               by|\n",
      "|Ulysses|            james|\n",
      "|Ulysses|            joyce|\n",
      "|Ulysses|             this|\n",
      "|Ulysses|            ebook|\n",
      "|Ulysses|               is|\n",
      "|Ulysses|              for|\n",
      "|Ulysses|              the|\n",
      "|Ulysses|              use|\n",
      "|Ulysses|               of|\n",
      "|Ulysses|           anyone|\n",
      "|Ulysses|         anywhere|\n",
      "|Ulysses|               at|\n",
      "|Ulysses|               no|\n",
      "+-------+-----------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "lines_by_book_2 = lines_by_book.withColumn('word', f.explode(f.split(f.col('value'), ' '))).where(f.length('word')>0)\\\n",
    ".select('book', f.lower(f.trim(f.col('word')))).alias('word').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_by_book_2 = lines_by_book\\\n",
    "    .select('book', f.explode(f.split('value', '[\\W_]+')).alias('word'))\\\n",
    "    .where(f.length('word') > 0)\\\n",
    "    .select('book', f.trim(f.lower(f.col('word'))).alias('word'))\\\n",
    "    .filter(f.col('word').isin(StopWords) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|   book|        word|\n",
      "+-------+------------+\n",
      "|Ulysses|     project|\n",
      "|Ulysses|   gutenberg|\n",
      "|Ulysses|       ebook|\n",
      "|Ulysses|     ulysses|\n",
      "|Ulysses|       james|\n",
      "|Ulysses|       joyce|\n",
      "|Ulysses|       ebook|\n",
      "|Ulysses|         use|\n",
      "|Ulysses|      anyone|\n",
      "|Ulysses|    anywhere|\n",
      "|Ulysses|        cost|\n",
      "|Ulysses|      almost|\n",
      "|Ulysses|restrictions|\n",
      "|Ulysses|  whatsoever|\n",
      "|Ulysses|         may|\n",
      "|Ulysses|        copy|\n",
      "|Ulysses|        give|\n",
      "|Ulysses|        away|\n",
      "|Ulysses|         use|\n",
      "|Ulysses|       terms|\n",
      "+-------+------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "lines_by_book_2.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   word|count|\n",
      "+-------+-----+\n",
      "|   said| 1823|\n",
      "|stephen| 1004|\n",
      "|  bloom| 1001|\n",
      "|    one|  965|\n",
      "|   like|  951|\n",
      "|     mr|  855|\n",
      "|    old|  603|\n",
      "|    man|  563|\n",
      "|    see|  521|\n",
      "|   eyes|  502|\n",
      "|   time|  498|\n",
      "|   says|  494|\n",
      "| father|  480|\n",
      "|   back|  479|\n",
      "|    two|  470|\n",
      "|    god|  470|\n",
      "|    yes|  434|\n",
      "|   know|  432|\n",
      "| little|  420|\n",
      "|   good|  412|\n",
      "+-------+-----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "lines_by_book_3 = lines_by_book_2.groupby('word').count().orderBy('count',ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+------------------+\n",
      "|    book|       word|c_d|i_d|               idf|\n",
      "+--------+-----------+---+---+------------------+\n",
      "| Ulysses|     borneo|  2|  1|0.6931471805599453|\n",
      "| Ulysses|delectation|  2|  1|0.6931471805599453|\n",
      "| Ulysses|  boulevard|  2|  1|0.6931471805599453|\n",
      "| Ulysses|       1903|  2|  1|0.6931471805599453|\n",
      "| Ulysses|       bros|  2|  1|0.6931471805599453|\n",
      "| Ulysses|  capacious|  2|  1|0.6931471805599453|\n",
      "|Portrait|  cardboard|  2|  1|0.6931471805599453|\n",
      "| Ulysses|     akasic|  2|  1|0.6931471805599453|\n",
      "|Portrait|   chaplets|  2|  1|0.6931471805599453|\n",
      "| Ulysses|  assessors|  2|  1|0.6931471805599453|\n",
      "|Portrait|   colleges|  2|  1|0.6931471805599453|\n",
      "| Ulysses|       babe|  2|  1|0.6931471805599453|\n",
      "| Ulysses|  comerford|  2|  1|0.6931471805599453|\n",
      "| Ulysses| bassoonist|  2|  1|0.6931471805599453|\n",
      "| Ulysses| comerfords|  2|  1|0.6931471805599453|\n",
      "| Ulysses|    blooded|  2|  1|0.6931471805599453|\n",
      "| Ulysses|      coral|  2|  1|0.6931471805599453|\n",
      "| Ulysses|       10th|  2|  1|0.6931471805599453|\n",
      "| Ulysses|   coutille|  2|  1|0.6931471805599453|\n",
      "| Ulysses| bunchiness|  2|  1|0.6931471805599453|\n",
      "+--------+-----------+---+---+------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = Window.partitionBy(lines_by_book_2['word'])\n",
    "c_d = lines_by_book_2.select('book').distinct().count()\n",
    "\n",
    "lines_by_book_2.groupby('book', 'word').agg(f.lit(c_d).alias('c_d'), f.count('*').over(w).alias('i_d'),\\\n",
    "        (f.log(f.lit(c_d)/f.count('*').over(w))).alias('idf')).orderBy('idf', ascending=False).show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
